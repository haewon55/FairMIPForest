{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  [COMPAS] Exponentiated Gradient Reduction\n",
    "\n",
    "Exponentiated gradient reduction is an in-processing technique that reduces fair classification to a sequence of cost-sensitive classification problems, returning a randomized classifier with the lowest empirical error subject to \n",
    "fair classification constraints. The code for exponentiated gradient reduction wraps the source class \n",
    "`fairlearn.reductions.ExponentiatedGradient` available in the https://github.com/fairlearn/fairlearn library,\n",
    "licensed under the MIT Licencse, Copyright Microsoft Corporation.\n",
    "\n",
    "This version of exponentiated gradient reduction (implemented in `aif360.algorithms`) wraps the sklearn compatible version of exponentiated gradient reduction implemented in `aif360.sklearn`. For a detailed tutorial on sklearn compatible exponentiated gradient reduction see [examples/sklearn/demo_exponentiated_gradient_reduction_sklearn.ipynb](sklearn/demo_exponentiated_gradient_reduction_sklearn.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "cwd = '../../../core'\n",
    "sys.path.append(cwd)\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset, StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult, load_preproc_data_compas, load_preproc_data_german\n",
    "\n",
    "from aif360.algorithms.inprocessing.exponentiated_gradient_reduction import ExponentiatedGradientReduction\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from load_compas import * \n",
    "from missing_module import * \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y, x_control = load_compas_data()\n",
    "\n",
    "df = pd.DataFrame(X, columns= ['age_cat_25 - 45', 'age_cat_Greater than 45', 'age_cat_Less than 25', 'race', 'sex', \n",
    "                               'priors_count', 'c_charge_degree'])\n",
    "\n",
    "idxx = df[df['race']==0].index\n",
    "print(idxx[:10])\n",
    "\n",
    "y = pd.Series(y, name=\"two_year_recid\")\n",
    "y[y==-1] = 0\n",
    "\n",
    "df = pd.concat([df, y], axis=1)\n",
    "df_bal = balance_data(df, 'race', 0)\n",
    "df_train, df_test = train_test_split(df_bal, test_size=0.3, random_state=0)\n",
    "\n",
    "s = 777\n",
    "df_ms = generate_missing(df_bal, c_label='race', ms_label='sex', p_ms0=0.4, p_ms1=0.1, seed=s)\n",
    "df_ms = generate_missing(df_ms, c_label='race', ms_label='priors_count', p_ms0=0.6, p_ms1=0.2, seed=s)\n",
    "\n",
    "\n",
    "privileged_groups = [{'race': 1}]\n",
    "unprivileged_groups = [{'race': 0}]\n",
    "\n",
    "df_ms.groupby(df_ms['race']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eps_list = [0.001, 0.005, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "fr_mean, acc_mean, fr_std, acc_std = [], [], [], [] \n",
    "\n",
    "\n",
    "for eps in eps_list: \n",
    "    fr_list = []\n",
    "    acc_list = [] \n",
    "    \n",
    "    for seed in range (1, 11): \n",
    "        dataset_orig_train, dataset_orig_test = train_test_split(df_ms, test_size=0.3, random_state=seed)\n",
    "\n",
    "        dataset_orig_train_no_sens = dataset_orig_train.drop(columns=['race','two_year_recid'])\n",
    "        dataset_orig_test_no_sens = dataset_orig_test.drop(columns=['race','two_year_recid'])\n",
    "\n",
    "        ## Change the following two lines to get mean or k-nn results ##\n",
    "#         imputer = SimpleImputer()\n",
    "        imputer = KNNImputer()\n",
    "\n",
    "        dataset_orig_train_no_sens = pd.DataFrame(imputer.fit_transform(dataset_orig_train_no_sens), \n",
    "                                                  columns=dataset_orig_train_no_sens.columns, \n",
    "                                                  index=dataset_orig_train_no_sens.index)\n",
    "        dataset_orig_test_no_sens = pd.DataFrame(imputer.transform(dataset_orig_test_no_sens), \n",
    "                                                 columns=dataset_orig_test_no_sens.columns, \n",
    "                                                 index=dataset_orig_test_no_sens.index)\n",
    "        dataset_orig_train = pd.concat([dataset_orig_train_no_sens, dataset_orig_train[['race','two_year_recid']]], axis=1)\n",
    "        dataset_orig_test = pd.concat([dataset_orig_test_no_sens, dataset_orig_test[['race','two_year_recid']]], axis=1)\n",
    "\n",
    "    #     print(dataset_orig_test.columns.to_list())\n",
    "    #     dataset_orig_train = dataset_orig_train.fillna(dataset_orig_train.mean())\n",
    "    #     dataset_orig_test = dataset_orig_test.fillna(dataset_orig_test.mean())\n",
    "\n",
    "        ### Converting to AIF360 StandardDataset objects ###\n",
    "        dataset_orig_train = StandardDataset(dataset_orig_train, label_name='two_year_recid', favorable_classes=[1],\n",
    "                                             protected_attribute_names=['race'], privileged_classes=[[1]])\n",
    "        dataset_orig_test = StandardDataset(dataset_orig_test, label_name='two_year_recid', favorable_classes=[1],\n",
    "                                             protected_attribute_names=['race'], privileged_classes=[[1]])\n",
    "\n",
    "        X_train = dataset_orig_train.features[:,:-1]\n",
    "        y_train = dataset_orig_train.labels.ravel()\n",
    "\n",
    "        lmod = DecisionTreeClassifier(max_depth=3)\n",
    "        lmod.fit(X_train, y_train, sample_weight=dataset_orig_train.instance_weights)\n",
    "\n",
    "        X_test = dataset_orig_test.features[:,:-1]\n",
    "        y_test = dataset_orig_test.labels.ravel()\n",
    "\n",
    "        y_pred = lmod.predict(X_test)\n",
    "\n",
    "        dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "        dataset_orig_test_pred.labels = y_pred\n",
    "\n",
    "        cm_pred_test = ClassificationMetric(dataset_orig_test, dataset_orig_test_pred,\n",
    "                                 unprivileged_groups=unprivileged_groups,\n",
    "                                 privileged_groups=privileged_groups)\n",
    "\n",
    "        display(Markdown(\"#### Original-Predicted testing dataset\"))\n",
    "        print(\"Difference in FNR between unprivileged and privileged groups\")\n",
    "        print(cm_pred_test.difference(cm_pred_test.false_negative_rate))\n",
    "\n",
    "        print(\"Overall Test Accuracy \")\n",
    "        print(cm_pred_test.accuracy())\n",
    "\n",
    "        estimator = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "        np.random.seed(0)\n",
    "        exp_grad_red = ExponentiatedGradientReduction(estimator=estimator, constraints=\"TruePositiveRateDifference\",\n",
    "                                                      drop_prot_attr=False, eps= eps)\n",
    "        exp_grad_red.fit(dataset_orig_train)\n",
    "        exp_grad_red_pred = exp_grad_red.predict(dataset_orig_test)\n",
    "\n",
    "        cm_transf_test = ClassificationMetric(dataset_orig_test, exp_grad_red_pred,\n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "        display(Markdown(\"#### Original-Transformed testing dataset\"))\n",
    "        print(\"Difference in FNR between unprivileged and privileged groups\")\n",
    "        fr = np.abs(cm_transf_test.difference(cm_transf_test.false_negative_rate))\n",
    "        fr_list.append(fr)\n",
    "        print(fr)\n",
    "\n",
    "        print(\"Overall Test Accuracy \")\n",
    "        acc = cm_transf_test.accuracy()\n",
    "        acc_list.append(acc)\n",
    "        print(acc)\n",
    "        \n",
    "    fr_mean.append(np.mean(fr_list))\n",
    "    fr_std.append(np.std(fr_list))\n",
    "    acc_mean.append(np.mean(acc_list))\n",
    "    acc_std.append(np.std(acc_list))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(fr_mean, ens_acc_mean, color='blue')\n",
    "plt.errorbar(fr_mean, acc_mean, xerr =fr_std, yerr=acc_std, fmt=\"o\", color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('knn_exp_grad_result.pkl', 'wb+') as f: \n",
    "    pickle.dump({'fr_mean': fr_mean, 'fr_std': fr_std, 'acc_mean': acc_mean, 'acc_std': acc_std}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
